{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMc11XLFcnuk"
   },
   "source": [
    "# Assignment 2:  Study Helper with Structured Tools\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Application with Tools and Function Calling Capabilities\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This assignment enhances the Study Helper agent from Assignment 1 by implementing:\n",
    "- Structured tool definitions using JSON Schema\n",
    "- Native LLM function calling capabilities\n",
    "- Improved error handling and validation\n",
    "- Multi-parameter tools with different data types\n",
    "\n",
    "### Key Improvements from Assignment 1:\n",
    "1. **Structured Tools**: Moved from manual JSON parsing to native function calling\n",
    "2. **Better Validation**: LLM validates inputs before execution\n",
    "3. **Industry Standards**: Using JSON Schema for tool definitions\n",
    "4. **Enhanced Robustness**: Proper error handling and type checking\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKSpTs5Acnuo"
   },
   "source": [
    "## Part 1: Setup and Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18047,
     "status": "ok",
     "timestamp": 1770876405879,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "qXz2qrRVcnup",
    "outputId": "f1553c13-3877-434b-9e04-3dff5cccdc17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting litellm\n",
      "  Downloading litellm-1.81.10-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.13.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm) (8.3.1)\n",
      "Collecting fastuuid>=0.13.0 (from litellm)\n",
      "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (4.26.0)\n",
      "Requirement already satisfied: openai>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (2.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (2.12.3)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm) (0.22.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.30.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (0.13.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.4)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm) (1.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (0.21.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.5.0)\n",
      "Downloading litellm-1.81.10-py3-none-any.whl (14.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastuuid, litellm\n",
      "Successfully installed fastuuid-0.14.0 litellm-1.81.10\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install required library\n",
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9779,
     "status": "ok",
     "timestamp": 1770876420933,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "3SFcCG5Ycnuq",
    "outputId": "ed4ea8dd-d9df-40e6-8ea1-24b922c08f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "from litellm import completion\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1770876423151,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "DAS8MVYhcnuq",
    "outputId": "0cf938c0-1ade-4ad2-8ac7-a8f7e4dbda55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key configured\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Configure API key\n",
    "# For Groq API (keys starting with 'gsk_')\n",
    "os.environ[\"GROQ_API_KEY\"] = \"Enter Your APi\"\n",
    "\n",
    "# For OpenAI API (keys starting with 'sk-')\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "\n",
    "print(\"API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "046ZJc03cnur"
   },
   "source": [
    "---\n",
    "## Part 2: Tool Function Implementations\n",
    "\n",
    "These are the actual Python functions that will be called by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1770876433730,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "j0BbP9Yycnur",
    "outputId": "bef87e07-7eb2-4722-899b-bcb2c1f339be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_quiz function defined\n"
     ]
    }
   ],
   "source": [
    "# Global storage for study notes\n",
    "study_notes = {}\n",
    "\n",
    "def generate_quiz(topic: str, num_questions: int = 5, difficulty: str = \"medium\") -> dict:\n",
    "    \"\"\"\n",
    "    Generate a quiz on a given topic.\n",
    "\n",
    "    Args:\n",
    "        topic: The subject for the quiz\n",
    "        num_questions: Number of questions to generate\n",
    "        difficulty: Difficulty level (easy, medium, hard)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing quiz information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Generating {num_questions} {difficulty} questions about {topic}...\")\n",
    "\n",
    "        # Create prompt for quiz generation\n",
    "        quiz_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert educational quiz creator.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Create {num_questions} multiple-choice quiz questions about {topic} at {difficulty} difficulty level.\n",
    "\n",
    "For each question provide:\n",
    "1. A clear question\n",
    "2. Four answer options (A, B, C, D)\n",
    "3. The correct answer letter\n",
    "4. A brief explanation\n",
    "\n",
    "Format each question:\n",
    "\n",
    "Q1: [Question text]\n",
    "A) [Option A]\n",
    "B) [Option B]\n",
    "C) [Option C]\n",
    "D) [Option D]\n",
    "Correct: [Letter]\n",
    "Explanation: [Brief explanation]\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Determine model based on API key\n",
    "        if os.environ.get(\"GROQ_API_KEY\"):\n",
    "            model = \"groq/llama-3.3-70b-versatile\"\n",
    "        else:\n",
    "            model = \"openai/gpt-4o\"\n",
    "\n",
    "        response = completion(\n",
    "            model=model,\n",
    "            messages=quiz_prompt,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        quiz_content = response.choices[0].message.content\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"topic\": topic,\n",
    "            \"num_questions\": num_questions,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"quiz_content\": quiz_content\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"generate_quiz function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1770876438653,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "mE-dLIO1cnur",
    "outputId": "37513d6f-f9de-4c6a-c163-13be88e3f2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize_text function defined\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(text: str, max_length: int = 100, include_keywords: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Summarize provided text with optional keyword extraction.\n",
    "\n",
    "    Args:\n",
    "        text: The text to summarize\n",
    "        max_length: Target summary length in words\n",
    "        include_keywords: Whether to extract key terms\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing summary and optional keywords\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Summarizing text (target length: {max_length} words, keywords: {include_keywords})...\")\n",
    "\n",
    "        keyword_instruction = \"Also extract 5-7 key terms or concepts.\" if include_keywords else \"\"\n",
    "\n",
    "        summary_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert at creating concise summaries.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Summarize the following text in approximately {max_length} words. {keyword_instruction}\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Provide:\n",
    "1. Summary\n",
    "2. Key points (3-5 bullet points)\n",
    "{\"3. Keywords\" if include_keywords else \"\"}\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        if os.environ.get(\"GROQ_API_KEY\"):\n",
    "            model = \"groq/llama-3.3-70b-versatile\"\n",
    "        else:\n",
    "            model = \"openai/gpt-4o\"\n",
    "\n",
    "        response = completion(\n",
    "            model=model,\n",
    "            messages=summary_prompt,\n",
    "            max_tokens=512\n",
    "        )\n",
    "\n",
    "        summary_content = response.choices[0].message.content\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"original_length\": len(text.split()),\n",
    "            \"target_length\": max_length,\n",
    "            \"summary\": summary_content,\n",
    "            \"keywords_included\": include_keywords\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"summarize_text function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1770876443920,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "mOt8bFSXcnus",
    "outputId": "2eda6fb1-2628-45f1-afc8-b81aabde5c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain_concept function defined\n"
     ]
    }
   ],
   "source": [
    "def explain_concept(concept: str, difficulty: str = \"simple\", include_examples: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Explain a concept at different difficulty levels.\n",
    "\n",
    "    Args:\n",
    "        concept: The concept to explain\n",
    "        difficulty: Level of explanation (simple, medium, detailed)\n",
    "        include_examples: Whether to include practical examples\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Explaining '{concept}' at {difficulty} level (examples: {include_examples})...\")\n",
    "\n",
    "        difficulty_instructions = {\n",
    "            \"simple\": \"Explain in simple terms suitable for beginners. Use analogies.\",\n",
    "            \"medium\": \"Provide a moderate explanation with some technical details.\",\n",
    "            \"detailed\": \"Give a comprehensive explanation with technical depth.\"\n",
    "        }\n",
    "\n",
    "        instruction = difficulty_instructions.get(difficulty, difficulty_instructions[\"simple\"])\n",
    "        examples_instruction = \"Include 2-3 practical examples.\" if include_examples else \"Focus on theory without examples.\"\n",
    "\n",
    "        explain_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert educator.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{instruction}\\n{examples_instruction}\\n\\nConcept: {concept}\\n\\nProvide a clear explanation with key takeaways.\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        if os.environ.get(\"GROQ_API_KEY\"):\n",
    "            model = \"groq/llama-3.3-70b-versatile\"\n",
    "        else:\n",
    "            model = \"openai/gpt-4o\"\n",
    "\n",
    "        response = completion(\n",
    "            model=model,\n",
    "            messages=explain_prompt,\n",
    "            max_tokens=768\n",
    "        )\n",
    "\n",
    "        explanation = response.choices[0].message.content\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"concept\": concept,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"examples_included\": include_examples,\n",
    "            \"explanation\": explanation\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"explain_concept function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1770876448005,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "0QD80YeUcnut",
    "outputId": "0cf4ee8f-3e1b-42e2-8905-57c929bd1b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_text function defined (NEW multi-parameter tool)\n"
     ]
    }
   ],
   "source": [
    "def analyze_text(text: str, language: str = \"en\", check_grammar: bool = False, word_count: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze text for various metrics and properties.\n",
    "    NEW MULTI-PARAMETER TOOL for Assignment 2.\n",
    "\n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "        language: Language code (en, es, fr, ur)\n",
    "        check_grammar: Whether to check for grammatical errors\n",
    "        word_count: Whether to include detailed word statistics\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Analyzing text (language: {language}, grammar: {check_grammar}, stats: {word_count})...\")\n",
    "\n",
    "        # Basic statistics\n",
    "        words = text.split()\n",
    "        chars = len(text)\n",
    "        sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "\n",
    "        result = {\n",
    "            \"status\": \"success\",\n",
    "            \"language\": language,\n",
    "            \"basic_stats\": {\n",
    "                \"character_count\": chars,\n",
    "                \"word_count\": len(words),\n",
    "                \"sentence_count\": sentences\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Detailed word analysis if requested\n",
    "        if word_count:\n",
    "            avg_word_length = sum(len(w) for w in words) / len(words) if words else 0\n",
    "            result[\"detailed_stats\"] = {\n",
    "                \"average_word_length\": round(avg_word_length, 2),\n",
    "                \"longest_word\": max(words, key=len) if words else None,\n",
    "                \"shortest_word\": min(words, key=len) if words else None\n",
    "            }\n",
    "\n",
    "        # Grammar check using LLM if requested\n",
    "        if check_grammar:\n",
    "            grammar_prompt = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"You are a grammar expert for {language} language.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Check this text for grammatical errors and provide brief feedback:\\n\\n{text}\"\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            if os.environ.get(\"GROQ_API_KEY\"):\n",
    "                model = \"groq/llama-3.3-70b-versatile\"\n",
    "            else:\n",
    "                model = \"openai/gpt-4o\"\n",
    "\n",
    "            response = completion(\n",
    "                model=model,\n",
    "                messages=grammar_prompt,\n",
    "                max_tokens=256\n",
    "            )\n",
    "\n",
    "            result[\"grammar_check\"] = response.choices[0].message.content\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"analyze_text function defined (NEW multi-parameter tool)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1770876451820,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "2FF2iIxOcnut",
    "outputId": "24e198e6-21b0-40e7-e445-8e9c6583289b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_notes function defined\n"
     ]
    }
   ],
   "source": [
    "def save_notes(title: str, content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Save study notes for later retrieval.\n",
    "\n",
    "    Args:\n",
    "        title: Title for the notes\n",
    "        content: Content to save\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with save status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        study_notes[title] = content\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Notes '{title}' saved successfully\",\n",
    "            \"total_notes\": len(study_notes)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"save_notes function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1770876456569,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "ofHIE95bcnuu",
    "outputId": "48b932c2-b3a0-424a-8477-740b30645d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve_notes function defined\n"
     ]
    }
   ],
   "source": [
    "def retrieve_notes(title: Optional[str] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve saved study notes.\n",
    "\n",
    "    Args:\n",
    "        title: Specific note title (optional)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with notes or list of titles\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if title:\n",
    "            if title in study_notes:\n",
    "                return {\n",
    "                    \"status\": \"success\",\n",
    "                    \"title\": title,\n",
    "                    \"content\": study_notes[title]\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"message\": f\"Notes '{title}' not found\"\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"available_notes\": list(study_notes.keys()),\n",
    "                \"total\": len(study_notes)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"retrieve_notes function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f8JJqnTcnuu"
   },
   "source": [
    "---\n",
    "## Part 3: Structured Tool Definitions (JSON Schema)\n",
    "\n",
    "This is the key improvement from Assignment 1. We define tools using JSON Schema format that LLMs understand natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1770876460201,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "sDa6j1zTcnux",
    "outputId": "a39b46f2-4b5e-4ad0-9ac4-30a19ba67524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool function mapping created\n"
     ]
    }
   ],
   "source": [
    "# Map tool names to actual functions\n",
    "tool_functions = {\n",
    "    \"generate_quiz\": generate_quiz,\n",
    "    \"summarize_text\": summarize_text,\n",
    "    \"explain_concept\": explain_concept,\n",
    "    \"analyze_text\": analyze_text,\n",
    "    \"save_notes\": save_notes,\n",
    "    \"retrieve_notes\": retrieve_notes\n",
    "}\n",
    "\n",
    "print(\"Tool function mapping created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1770876463775,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "dalT9WGacnux",
    "outputId": "792fbce2-11fd-4ed7-f5bb-37772c8140a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 6 structured tools using JSON Schema\n"
     ]
    }
   ],
   "source": [
    "# Define structured tool schemas for LLM\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_quiz\",\n",
    "            \"description\": \"Generate a multiple-choice quiz on any topic with customizable difficulty and number of questions.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The subject or topic for the quiz\"\n",
    "                    },\n",
    "                    \"num_questions\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Number of questions to generate\",\n",
    "                        \"default\": 5\n",
    "                    },\n",
    "                    \"difficulty\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"easy\", \"medium\", \"hard\"],\n",
    "                        \"description\": \"Difficulty level of the quiz\",\n",
    "                        \"default\": \"medium\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"summarize_text\",\n",
    "            \"description\": \"Summarize provided text with optional keyword extraction.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The text to summarize\"\n",
    "                    },\n",
    "                    \"max_length\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Target summary length in words\",\n",
    "                        \"default\": 100\n",
    "                    },\n",
    "                    \"include_keywords\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether to extract key terms\",\n",
    "                        \"default\": True\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"explain_concept\",\n",
    "            \"description\": \"Explain a concept at different difficulty levels with optional examples.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"concept\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The concept to explain\"\n",
    "                    },\n",
    "                    \"difficulty\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"simple\", \"medium\", \"detailed\"],\n",
    "                        \"description\": \"Level of explanation detail\",\n",
    "                        \"default\": \"simple\"\n",
    "                    },\n",
    "                    \"include_examples\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether to include practical examples\",\n",
    "                        \"default\": True\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"concept\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_text\",\n",
    "            \"description\": \"Analyze text for various metrics including word count, grammar, and language-specific features. NEW multi-parameter tool.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The text to analyze\"\n",
    "                    },\n",
    "                    \"language\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"en\", \"es\", \"fr\", \"ur\"],\n",
    "                        \"description\": \"Language code for analysis\",\n",
    "                        \"default\": \"en\"\n",
    "                    },\n",
    "                    \"check_grammar\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether to check for grammatical errors\",\n",
    "                        \"default\": False\n",
    "                    },\n",
    "                    \"word_count\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether to include detailed word statistics\",\n",
    "                        \"default\": True\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"save_notes\",\n",
    "            \"description\": \"Save study notes for later retrieval.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Title for the notes\"\n",
    "                    },\n",
    "                    \"content\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Content to save\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"title\", \"content\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"retrieve_notes\",\n",
    "            \"description\": \"Retrieve saved study notes. If no title provided, lists all available notes.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Specific note title to retrieve (optional)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(tools)} structured tools using JSON Schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbmvwSFZcnuz"
   },
   "source": [
    "---\n",
    "## Part 4: Agent System Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1770876470377,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "04qNqTz3cnuz",
    "outputId": "79a2145e-ae7f-4c8b-db10-776ffe90213a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent system rules defined\n"
     ]
    }
   ],
   "source": [
    "# Agent system rules (simplified with native function calling)\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are a Study Helper AI agent that assists students with learning.\n",
    "\n",
    "You have access to several tools for helping students:\n",
    "- generate_quiz: Create quizzes on any topic\n",
    "- summarize_text: Summarize long texts\n",
    "- explain_concept: Explain concepts at different levels\n",
    "- analyze_text: Analyze text for grammar, statistics, and language features\n",
    "- save_notes: Save study materials\n",
    "- retrieve_notes: Access saved materials\n",
    "\n",
    "Always choose the most appropriate tool for the user's request.\n",
    "Be helpful, encouraging, and educational in your responses.\n",
    "\"\"\"\n",
    "}]\n",
    "\n",
    "print(\"Agent system rules defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkMFEKZfcnuz"
   },
   "source": [
    "---\n",
    "## Part 5: Agent Loop with Native Function Calling\n",
    "\n",
    "This is the major improvement from Assignment 1. We now use the LLM's native function calling instead of manual JSON parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1770876488580,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "BRfKGQXDcnu0",
    "outputId": "1bdb402b-8955-458a-b17c-8d54e3271396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced agent loop defined\n"
     ]
    }
   ],
   "source": [
    "def run_enhanced_agent(max_iterations: int = 10):\n",
    "    \"\"\"\n",
    "    Enhanced agent loop using native LLM function calling.\n",
    "\n",
    "    Key improvements from Assignment 1:\n",
    "    1. Uses 'tools' parameter in completion call\n",
    "    2. No manual JSON parsing required\n",
    "    3. Better error handling with validation\n",
    "    4. Native tool_calls extraction\n",
    "\n",
    "    Args:\n",
    "        max_iterations: Maximum number of interactions\n",
    "    \"\"\"\n",
    "    # Initialize memory\n",
    "    memory = agent_rules.copy()\n",
    "    iterations = 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Study Helper Agent - Enhanced with Structured Tools\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAvailable capabilities:\")\n",
    "    print(\"  - Generate quizzes with custom difficulty\")\n",
    "    print(\"  - Summarize text with keyword extraction\")\n",
    "    print(\"  - Explain concepts at different levels\")\n",
    "    print(\"  - Analyze text (NEW: grammar, stats, multi-language)\")\n",
    "    print(\"  - Save and retrieve study notes\")\n",
    "    print(\"\\nType 'quit' or 'exit' to end session.\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    while iterations < max_iterations:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "\n",
    "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "            print(\"\\nSession ended. Thank you for using Study Helper.\")\n",
    "            break\n",
    "\n",
    "        if not user_input:\n",
    "            print(\"Please enter a message.\")\n",
    "            continue\n",
    "\n",
    "        # Add user message to memory\n",
    "        memory.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        try:\n",
    "            # Determine model\n",
    "            if os.environ.get(\"GROQ_API_KEY\"):\n",
    "                model = \"groq/llama-3.3-70b-versatile\"\n",
    "            else:\n",
    "                model = \"openai/gpt-4o\"\n",
    "\n",
    "            print(\"\\nAgent: Processing...\")\n",
    "\n",
    "            # Call LLM with structured tools (KEY IMPROVEMENT)\n",
    "            response = completion(\n",
    "                model=model,\n",
    "                messages=memory,\n",
    "                tools=tools,  # Pass structured tool definitions\n",
    "                max_tokens=1024\n",
    "            )\n",
    "\n",
    "            message = response.choices[0].message\n",
    "\n",
    "            # Check if LLM wants to use a tool\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                # Extract tool call (no manual parsing needed!)\n",
    "                tool_call = message.tool_calls[0]\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nCalling tool: {tool_name}\")\n",
    "                print(f\"Arguments: {json.dumps(tool_args, indent=2)}\")\n",
    "\n",
    "                # Validate tool exists\n",
    "                if tool_name not in tool_functions:\n",
    "                    result = {\n",
    "                        \"status\": \"error\",\n",
    "                        \"message\": f\"Tool '{tool_name}' not found\"\n",
    "                    }\n",
    "                else:\n",
    "                    # Execute the tool function\n",
    "                    try:\n",
    "                        result = tool_functions[tool_name](**tool_args)\n",
    "                    except TypeError as e:\n",
    "                        result = {\n",
    "                            \"status\": \"error\",\n",
    "                            \"message\": f\"Invalid arguments for {tool_name}: {str(e)}\"\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        result = {\n",
    "                            \"status\": \"error\",\n",
    "                            \"message\": f\"Error executing {tool_name}: {str(e)}\"\n",
    "                        }\n",
    "\n",
    "                # Display result\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"Result:\")\n",
    "                print(\"=\"*60)\n",
    "\n",
    "                if isinstance(result, dict):\n",
    "                    for key, value in result.items():\n",
    "                        if key != 'status':\n",
    "                            if isinstance(value, str) and len(value) > 300:\n",
    "                                print(f\"\\n{key}:\")\n",
    "                                print(value)\n",
    "                            else:\n",
    "                                print(f\"{key}: {value}\")\n",
    "                else:\n",
    "                    print(result)\n",
    "\n",
    "                print(\"=\"*60)\n",
    "\n",
    "                # Update memory with assistant message and tool result\n",
    "                memory.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": None,\n",
    "                    \"tool_calls\": [{\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": tool_name,\n",
    "                            \"arguments\": tool_call.function.arguments\n",
    "                        }\n",
    "                    }]\n",
    "                })\n",
    "\n",
    "                memory.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                # No tool call, just a regular response\n",
    "                print(f\"\\nAgent: {message.content}\")\n",
    "                memory.append({\"role\": \"assistant\", \"content\": message.content})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            print(\"Please try again.\")\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    if iterations >= max_iterations:\n",
    "        print(\"\\nMaximum iterations reached. Session ended.\")\n",
    "\n",
    "print(\"Enhanced agent loop defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3LrGyftcnu0"
   },
   "source": [
    "---\n",
    "## Part 6: Run the Enhanced Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45994,
     "status": "ok",
     "timestamp": 1770876540178,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "AMrEBr-ycnu1",
    "outputId": "159093f1-9d2b-40c0-c978-df21008d12cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Study Helper Agent - Enhanced with Structured Tools\n",
      "============================================================\n",
      "\n",
      "Available capabilities:\n",
      "  - Generate quizzes with custom difficulty\n",
      "  - Summarize text with keyword extraction\n",
      "  - Explain concepts at different levels\n",
      "  - Analyze text (NEW: grammar, stats, multi-language)\n",
      "  - Save and retrieve study notes\n",
      "\n",
      "Type 'quit' or 'exit' to end session.\n",
      "============================================================\n",
      "\n",
      "\n",
      "You: Create a quiz about Python programming with 3 questions\n",
      "\n",
      "Agent: Processing...\n",
      "\n",
      "Calling tool: generate_quiz\n",
      "Arguments: {\n",
      "  \"num_questions\": 3,\n",
      "  \"topic\": \"Python programming\"\n",
      "}\n",
      "Generating 3 medium questions about Python programming...\n",
      "\n",
      "============================================================\n",
      "Result:\n",
      "============================================================\n",
      "topic: Python programming\n",
      "num_questions: 3\n",
      "difficulty: medium\n",
      "\n",
      "quiz_content:\n",
      "Q1: What is the purpose of the \"self\" parameter in a Python class method?\n",
      "A) To access global variables\n",
      "B) To access class variables and methods\n",
      "C) To access local variables only\n",
      "D) To exit the program\n",
      "Correct: B\n",
      "Explanation: The \"self\" parameter is a reference to the current instance of the class and is used to access variables and methods that belongs to the class.\n",
      "\n",
      "Q2: What is the difference between the \"break\" and \"continue\" statements in a Python loop?\n",
      "A) \"break\" skips to the next iteration, while \"continue\" exits the loop\n",
      "B) \"break\" exits the loop, while \"continue\" skips to the next iteration\n",
      "C) \"break\" restarts the loop, while \"continue\" exits the program\n",
      "D) \"break\" exits the program, while \"continue\" restarts the loop\n",
      "Correct: B\n",
      "Explanation: The \"break\" statement exits the loop entirely, while the \"continue\" statement skips to the next iteration of the loop.\n",
      "\n",
      "Q3: What is the purpose of the \"try-except\" block in Python?\n",
      "A) To handle runtime errors and exceptions\n",
      "B) To optimize code performance\n",
      "C) To implement multithreading\n",
      "D) To access external libraries\n",
      "Correct: A\n",
      "Explanation: The \"try-except\" block is used to catch and handle runtime errors and exceptions, allowing the program to continue executing instead of crashing.\n",
      "============================================================\n",
      "\n",
      "You: Explain recursion in simple terms\n",
      "\n",
      "Agent: Processing...\n",
      "\n",
      "Calling tool: explain_concept\n",
      "Arguments: {\n",
      "  \"concept\": \"recursion\",\n",
      "  \"difficulty\": \"simple\"\n",
      "}\n",
      "Explaining 'recursion' at simple level (examples: True)...\n",
      "\n",
      "============================================================\n",
      "Result:\n",
      "============================================================\n",
      "concept: recursion\n",
      "difficulty: simple\n",
      "examples_included: True\n",
      "\n",
      "explanation:\n",
      "**Understanding Recursion: A Simple Explanation**\n",
      "\n",
      "Imagine you have a set of Russian nesting dolls, also known as matryoshka dolls. Each doll has a smaller doll inside it, and that smaller doll has an even smaller one inside it, and so on. This is similar to how recursion works in programming.\n",
      "\n",
      "**What is Recursion?**\n",
      "\n",
      "Recursion is a programming concept where a function calls itself repeatedly until it reaches a base case that stops the recursion. In other words, a function solves a problem by breaking it down into smaller instances of the same problem, which are then solved by the same function, until it reaches a solution.\n",
      "\n",
      "**How Recursion Works**\n",
      "\n",
      "Think of it like a staircase. You start at the top, and each step you take leads to another step that's similar, but smaller. You keep going down the stairs until you reach the bottom, which is the base case. Then, you start going back up, solving each step as you go.\n",
      "\n",
      "**Practical Examples**\n",
      "\n",
      "1. **Factorial Calculation**: Imagine you want to calculate the factorial of a number, which is the product of all positive integers up to that number. A recursive function would call itself with a smaller number until it reaches 1, which is the base case. For example, to calculate 4! (4 factorial), the function would call itself like this: 4! = 4 * 3!, then 3! = 3 * 2!, and so on, until it reaches 1! = 1.\n",
      "2. **Tree Traversal**: Suppose you have a tree-like structure, and you want to print all the nodes. A recursive function would visit each node, then call itself to visit the child nodes, until it reaches a node with no children (the base case).\n",
      "3. **Tower of Hanoi**: This classic puzzle involves moving a stack of disks from one pole to another, subject to certain rules. A recursive solution would involve moving the top disk to a temporary pole, then calling itself to move the remaining disks, until only one disk is left (the base case).\n",
      "\n",
      "**Key Takeaways**\n",
      "\n",
      "* Recursion involves a function calling itself repeatedly until it reaches a base case.\n",
      "* The base case is the smallest instance of the problem that can be solved directly.\n",
      "* Recursion can be used to solve problems that have a recursive structure, such as tree traversals or factorial calculations.\n",
      "* When using recursion, make sure to define a clear base case to avoid infinite loops.\n",
      "\n",
      "By understanding recursion, you can write more efficient and elegant code to solve complex problems. Just remember to break down the problem into smaller instances of itself, and define a clear base case to stop the recursion.\n",
      "============================================================\n",
      "\n",
      "You: exit\n",
      "\n",
      "Session ended. Thank you for using Study Helper.\n"
     ]
    }
   ],
   "source": [
    "# Run the enhanced agent\n",
    "run_enhanced_agent(max_iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeI4BKOCcnu1"
   },
   "source": [
    "---\n",
    "## Testing Scenarios\n",
    "\n",
    "### Test 1: Basic Tool Call\n",
    "```\n",
    "You: Create a quiz about Python programming with 3 questions\n",
    "Expected: Uses generate_quiz with appropriate parameters\n",
    "```\n",
    "\n",
    "### Test 2: Multi-Parameter Tool (NEW)\n",
    "```\n",
    "You: Analyze this text for grammar and check word count: \"The quick brown fox jumps over the lazy dog.\"\n",
    "Expected: Uses analyze_text with multiple parameters (text, check_grammar=true, word_count=true)\n",
    "```\n",
    "\n",
    "### Test 3: Error Handling\n",
    "```\n",
    "You: Generate a quiz on an invalid topic with negative questions\n",
    "Expected: Graceful error handling with helpful message\n",
    "```\n",
    "\n",
    "### Test 4: Memory Integration\n",
    "```\n",
    "You: Explain recursion in simple terms\n",
    "Agent: [Explains recursion]\n",
    "You: Now create a quiz about what you just explained\n",
    "Expected: Agent remembers previous explanation and creates relevant quiz\n",
    "```\n",
    "\n",
    "### Test 5: Multiple Tools in Sequence\n",
    "```\n",
    "You: Create a quiz about Machine Learning\n",
    "Agent: [Creates quiz]\n",
    "You: Save this quiz as \"ML Basics\"\n",
    "Agent: [Saves the quiz]\n",
    "You: Show me all my saved notes\n",
    "Agent: [Lists saved notes including \"ML Basics\"]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjaqGV5Hcnu2"
   },
   "source": [
    "## Key Improvements from Assignment 1\n",
    "\n",
    "### 1. Structured Tool Definitions\n",
    "**Before (Assignment 1):**\n",
    "```python\n",
    "# Manual JSON in prompt\n",
    "\"\"\"Respond with:\n",
    "{\n",
    "  \"tool_name\": \"generate_quiz\",\n",
    "  \"args\": {\"topic\": \"...\", \"num_questions\": 5}\n",
    "}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**After (Assignment 2):**\n",
    "```python\n",
    "# JSON Schema with validation\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"generate_quiz\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {...},\n",
    "      \"required\": [\"topic\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 2. Native Function Calling\n",
    "**Before:**\n",
    "```python\n",
    "# Manual parsing\n",
    "response = generate_response(messages)\n",
    "action = parse_action(response)  # Custom JSON extraction\n",
    "tool_name = action[\"tool_name\"]\n",
    "```\n",
    "\n",
    "**After:**\n",
    "```python\n",
    "# Native extraction\n",
    "response = completion(messages=messages, tools=tools)\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "tool_name = tool_call.function.name\n",
    "```\n",
    "\n",
    "### 3. Better Error Handling\n",
    "- Validation of tool existence\n",
    "- Type checking for arguments\n",
    "- Graceful failure messages\n",
    "- Try-except blocks at multiple levels\n",
    "\n",
    "### 4. Multi-Parameter Tool\n",
    "The new `analyze_text` function demonstrates:\n",
    "- String parameters (text, language)\n",
    "- Boolean parameters (check_grammar, word_count)\n",
    "- Enum values (language choices)\n",
    "- Optional parameters with defaults\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpA51ul7cnu2"
   },
   "source": [
    "## Benefits of Structured Approach\n",
    "\n",
    "### 1. Validation\n",
    "The LLM validates parameter types before calling functions, reducing errors.\n",
    "\n",
    "### 2. Clarity\n",
    "JSON Schema provides clear documentation of what each tool does and expects.\n",
    "\n",
    "### 3. Interoperability\n",
    "Tools can be shared across different applications and systems.\n",
    "\n",
    "### 4. Native Support\n",
    "Modern LLMs (GPT-4, Claude, Llama) support this format natively.\n",
    "\n",
    "### 5. Maintainability\n",
    "Easier to add, modify, or remove tools without changing prompts.\n",
    "\n",
    "### 6. Industry Standard\n",
    "Follows established patterns used in production systems.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
