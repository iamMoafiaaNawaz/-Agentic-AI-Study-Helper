{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hx46gSnZWAA"
   },
   "source": [
    "# Study Helper - Enhanced Agentic AI Application\n",
    "### Assignment 1: Building a Basic Agentic AI Application\n",
    "\n",
    "---\n",
    "\n",
    "## What This Agent Does\n",
    "This Study Helper agent uses **AI-powered tools** to:\n",
    "- **Generate quizzes** with real questions using LLM\n",
    "- **Summarize text** intelligently using LLM\n",
    "- **Explain concepts** with detailed AI-generated explanations\n",
    "- **Save study notes** for later reference\n",
    "- **Retrieve saved notes** to review\n",
    "\n",
    "The agent maintains memory across interactions and can chain multiple tools together!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L17XdWW2ZWAK"
   },
   "source": [
    "## Part 1: Setup and Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18133,
     "status": "ok",
     "timestamp": 1770875400404,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "EFg9rCqaZWAL",
    "outputId": "12137655-fa90-4d11-c14d-75d299348f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting litellm\n",
      "  Downloading litellm-1.81.10-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.13.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm) (8.3.1)\n",
      "Collecting fastuuid>=0.13.0 (from litellm)\n",
      "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (4.26.0)\n",
      "Requirement already satisfied: openai>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (2.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (2.12.3)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm) (0.22.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.30.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (0.13.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=2.8.0->litellm) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.4)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm) (1.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (0.21.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.5.0)\n",
      "Downloading litellm-1.81.10-py3-none-any.whl (14.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastuuid, litellm\n",
      "Successfully installed fastuuid-0.14.0 litellm-1.81.10\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install required library\n",
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1770875436059,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "fysZUVCbZWAM",
    "outputId": "33f70214-37f9-4e41-9ba7-822974eb08e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key configured!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set up API key\n",
    "import os\n",
    "\n",
    "# OPTION 1: For Groq API (if your key starts with 'gsk_')\n",
    "os.environ[\"GROQ_API_KEY\"] = \"Enter Your API\"\n",
    "\n",
    "# OPTION 2: For OpenAI API (if your key starts with 'sk-')\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "\n",
    "print(\"✓ API key configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4116,
     "status": "ok",
     "timestamp": 1770875443230,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "GSYsehk9ZWAN",
    "outputId": "c7dec65f-892d-4182-82e1-5a905f662440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Import necessary libraries\n",
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NOQJN5vZWAN"
   },
   "source": [
    "---\n",
    "## Part 2: Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1770875445748,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "AaJMMahIZWAO",
    "outputId": "7f5c9ce1-53e5-4738-bed7-8fc1b8af1afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ generate_response function defined!\n"
     ]
    }
   ],
   "source": [
    "# Generate response from LLM\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Call LLM to generate a response based on conversation history.\n",
    "\n",
    "    Args:\n",
    "        messages: List of message dictionaries with 'role' and 'content'\n",
    "\n",
    "    Returns:\n",
    "        String response from the LLM\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check which API key is set\n",
    "        if os.environ.get(\"GROQ_API_KEY\"):\n",
    "            # Use Groq with a compatible model\n",
    "            model = \"groq/llama-3.3-70b-versatile\"  # Fast and good for this task\n",
    "        else:\n",
    "            # Use OpenAI\n",
    "            model = \"openai/gpt-4o\"\n",
    "\n",
    "        response = completion(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "print(\"✓ generate_response function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1770875449315,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "EvA4TJmSZWAO",
    "outputId": "83380b2b-7447-44d0-d30b-6c459e51e0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ extract_markdown_block function defined!\n"
     ]
    }
   ],
   "source": [
    "# Helper function to extract markdown code blocks\n",
    "def extract_markdown_block(text: str, block_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract content from markdown code blocks.\n",
    "\n",
    "    Args:\n",
    "        text: The full text containing markdown blocks\n",
    "        block_type: The type of block to extract (e.g., 'action', 'json')\n",
    "\n",
    "    Returns:\n",
    "        Extracted content from the code block\n",
    "    \"\"\"\n",
    "    pattern = f\"```{block_type}\\\\n(.*?)\\\\n```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    # If no block type specified, try to find any code block\n",
    "    pattern = f\"```\\\\n(.*?)\\\\n```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text\n",
    "\n",
    "print(\"✓ extract_markdown_block function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1770875452396,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "9jox1XW4ZWAQ",
    "outputId": "31acd395-c153-4a29-f2d5-d61481bd75c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ parse_action function defined!\n"
     ]
    }
   ],
   "source": [
    "# Parse LLM response to extract action\n",
    "def parse_action(response: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse the LLM response into a structured action dictionary.\n",
    "\n",
    "    Args:\n",
    "        response: Raw response from LLM\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with 'tool_name' and 'args'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract the action block from markdown\n",
    "        response = extract_markdown_block(response, \"action\")\n",
    "        response_json = json.loads(response)\n",
    "\n",
    "        # Validate the response has required fields\n",
    "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
    "            return response_json\n",
    "        else:\n",
    "            return {\n",
    "                \"tool_name\": \"error\",\n",
    "                \"args\": {\"message\": \"Response must have 'tool_name' and 'args' fields.\"}\n",
    "            }\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"tool_name\": \"error\",\n",
    "            \"args\": {\"message\": \"Invalid JSON response. Please use proper JSON format.\"}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"tool_name\": \"error\",\n",
    "            \"args\": {\"message\": f\"Error parsing response: {str(e)}\"}\n",
    "        }\n",
    "\n",
    "print(\"✓ parse_action function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0r3H1ALZWAR"
   },
   "source": [
    "---\n",
    "## Part 3: Enhanced AI-Powered Tools\n",
    "\n",
    "These tools now use the LLM to generate real, intelligent responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1770875456353,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "vutGvTLCZWAR",
    "outputId": "debaa59b-394d-4a55-a18e-4451dce75837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ generate_quiz tool defined (AI-powered)!\n"
     ]
    }
   ],
   "source": [
    "# Global storage for notes\n",
    "study_notes = {}\n",
    "\n",
    "# Tool 1: Generate Quiz (AI-Powered)\n",
    "def generate_quiz(topic: str, num_questions: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a quiz on a given topic using AI.\n",
    "\n",
    "    Args:\n",
    "        topic: The subject for the quiz\n",
    "        num_questions: Number of questions to generate (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with AI-generated quiz questions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"    Generating {num_questions} quiz questions about {topic}...\")\n",
    "\n",
    "        # Create prompt for quiz generation\n",
    "        quiz_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert educational quiz creator.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Create {num_questions} multiple-choice quiz questions about {topic}.\n",
    "\n",
    "For each question, provide:\n",
    "1. A clear, educational question\n",
    "2. Four answer options (A, B, C, D)\n",
    "3. The correct answer letter\n",
    "4. A brief explanation\n",
    "\n",
    "Format each question like this:\n",
    "\n",
    "Q1: [Question text]\n",
    "A) [Option A]\n",
    "B) [Option B]\n",
    "C) [Option C]\n",
    "D) [Option D]\n",
    "Correct: [Letter]\n",
    "Explanation: [Brief explanation]\n",
    "\n",
    "Make the questions educational and progressively challenging.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Generate quiz using LLM\n",
    "        response = generate_response(quiz_prompt)\n",
    "\n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"num_questions\": num_questions,\n",
    "            \"quiz_content\": response,\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\" Generated {num_questions} AI-powered questions about {topic}\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"✓ generate_quiz tool defined (AI-powered)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1770875460329,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "aESp5lMvZWAV",
    "outputId": "ebde10c6-caeb-4dd6-881b-f4af91bdffaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ summarize_text tool defined (AI-powered)!\n"
     ]
    }
   ],
   "source": [
    "# Tool 2: Summarize Text (AI-Powered)\n",
    "def summarize_text(text: str, max_sentences: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    Summarize a given text using AI.\n",
    "\n",
    "    Args:\n",
    "        text: The text to summarize\n",
    "        max_sentences: Target number of sentences (default: 3)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with AI-generated summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"    Summarizing text (target: {max_sentences} sentences)...\")\n",
    "\n",
    "        # Create prompt for summarization\n",
    "        summary_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert at creating concise, clear summaries.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Summarize the following text in approximately {max_sentences} sentences.\n",
    "Focus on the main ideas and key points.\n",
    "\n",
    "Text to summarize:\n",
    "{text}\n",
    "\n",
    "Provide:\n",
    "1. A brief summary\n",
    "2. 3-5 key points as bullet points\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Generate summary using LLM\n",
    "        response = generate_response(summary_prompt)\n",
    "\n",
    "        return {\n",
    "            \"original_length\": len(text.split()),\n",
    "            \"summary\": response,\n",
    "            \"target_sentences\": max_sentences,\n",
    "            \"status\": \"success\",\n",
    "            \"message\": \" Text summarized successfully\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"✓ summarize_text tool defined (AI-powered)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1770875464714,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "KT26kab3ZWAX",
    "outputId": "ad226b3a-4992-459e-cc0f-e0dfd2f9a58f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ explain_concept tool defined (AI-powered)!\n"
     ]
    }
   ],
   "source": [
    "# Tool 3: Explain Concept (AI-Powered)\n",
    "def explain_concept(concept: str, difficulty: str = \"simple\") -> dict:\n",
    "    \"\"\"\n",
    "    Explain a concept using AI at different difficulty levels.\n",
    "\n",
    "    Args:\n",
    "        concept: The concept to explain\n",
    "        difficulty: 'simple', 'medium', or 'detailed' (default: 'simple')\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with AI-generated explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"    Explaining '{concept}' at {difficulty} level...\")\n",
    "\n",
    "        # Map difficulty to instruction\n",
    "        difficulty_map = {\n",
    "            \"simple\": \"Explain this in simple terms that a beginner can understand. Use analogies and examples.\",\n",
    "            \"medium\": \"Provide a moderate explanation with some technical details and practical examples.\",\n",
    "            \"detailed\": \"Give a comprehensive, detailed explanation including technical aspects, theory, and real-world applications.\"\n",
    "        }\n",
    "\n",
    "        instruction = difficulty_map.get(difficulty, difficulty_map[\"simple\"])\n",
    "\n",
    "        # Create prompt for explanation\n",
    "        explain_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert educator who can explain complex concepts clearly.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{instruction}\\n\\nConcept: {concept}\\n\\nProvide:\\n1. A clear explanation\\n2. 2-3 practical examples\\n3. Key takeaways\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Generate explanation using LLM\n",
    "        response = generate_response(explain_prompt)\n",
    "\n",
    "        return {\n",
    "            \"concept\": concept,\n",
    "            \"difficulty_level\": difficulty,\n",
    "            \"explanation\": response,\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\" Explained '{concept}' at {difficulty} level\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"✓ explain_concept tool defined (AI-powered)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1770875469160,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "l5KXlgTsZWAY",
    "outputId": "c3689782-2e18-4a14-8161-6f57256de7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ save_notes tool defined!\n"
     ]
    }
   ],
   "source": [
    "# Tool 4: Save Notes\n",
    "def save_notes(title: str, content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Save study notes for later retrieval.\n",
    "\n",
    "    Args:\n",
    "        title: Title/name for the notes\n",
    "        content: The note content\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with save status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        study_notes[title] = content\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\" Notes '{title}' saved successfully!\",\n",
    "            \"total_notes\": len(study_notes)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"✓ save_notes tool defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1770875472946,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "Mqcdv2a3ZWAY",
    "outputId": "ff396e8e-3b47-4234-8e32-102b8c7f36a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ retrieve_notes tool defined!\n"
     ]
    }
   ],
   "source": [
    "# Tool 5: Retrieve Notes\n",
    "def retrieve_notes(title: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve saved study notes.\n",
    "\n",
    "    Args:\n",
    "        title: Specific note title to retrieve (optional)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with notes or list of available notes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if title:\n",
    "            if title in study_notes:\n",
    "                return {\n",
    "                    \"status\": \"success\",\n",
    "                    \"title\": title,\n",
    "                    \"content\": study_notes[title],\n",
    "                    \"message\": f\" Retrieved notes: {title}\"\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"message\": f\" Notes '{title}' not found\"\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"available_notes\": list(study_notes.keys()),\n",
    "                \"total\": len(study_notes),\n",
    "                \"message\": f\" Found {len(study_notes)} saved notes\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "print(\"✓ retrieve_notes tool defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfqyQTpVZWAZ"
   },
   "source": [
    "---\n",
    "## Part 4: Agent Behavior Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1770875476658,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "Inj81FzFZWAa",
    "outputId": "e71e489f-456b-43e0-de26-998baf91d0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent rules defined!\n"
     ]
    }
   ],
   "source": [
    "# Define agent rules and behavior\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are a Study Helper AI agent designed to assist students with their learning.\n",
    "\n",
    "Available tools (ALL POWERED BY AI):\n",
    "\n",
    "1. generate_quiz(topic: str, num_questions: int) -> dict\n",
    "   - Creates AI-generated quiz with real questions\n",
    "   - num_questions: number of questions (default: 5)\n",
    "\n",
    "2. summarize_text(text: str, max_sentences: int) -> dict\n",
    "   - AI-powered text summarization with key points\n",
    "   - max_sentences: target summary length (default: 3)\n",
    "\n",
    "3. explain_concept(concept: str, difficulty: str) -> dict\n",
    "   - AI explains concepts with examples\n",
    "   - difficulty: 'simple', 'medium', or 'detailed' (default: 'simple')\n",
    "\n",
    "4. save_notes(title: str, content: str) -> dict\n",
    "   - Saves study notes for later retrieval\n",
    "\n",
    "5. retrieve_notes(title: str) -> dict\n",
    "   - Retrieves saved notes by title\n",
    "   - If no title provided, lists all available notes\n",
    "\n",
    "6. terminate(message: str)\n",
    "   - Ends the conversation with a summary\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Always respond with exactly ONE action per turn\n",
    "- Choose the most appropriate tool for the user's request\n",
    "- If the user wants to end the conversation, use terminate\n",
    "- Be helpful and encouraging to students\n",
    "- All tools use AI to generate high-quality responses\n",
    "\n",
    "Response format (you MUST follow this exactly):\n",
    "```action\n",
    "{\n",
    "  \"tool_name\": \"name_of_tool\",\n",
    "  \"args\": {\"arg1\": \"value1\", \"arg2\": \"value2\"}\n",
    "}\n",
    "```\n",
    "\n",
    "Example:\n",
    "User: \"Create a quiz about Python\"\n",
    "```action\n",
    "{\n",
    "  \"tool_name\": \"generate_quiz\",\n",
    "  \"args\": {\"topic\": \"Python programming\", \"num_questions\": 5}\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "}]\n",
    "\n",
    "print(\"✓ Agent rules defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbZN1t-9ZWAa"
   },
   "source": [
    "---\n",
    "## Part 5: Agent Loop Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1770875487711,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "NkY_PVDwZWAa",
    "outputId": "d46ed28e-ef59-433f-b2c4-464b2d0c5987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ run_agent function defined!\n"
     ]
    }
   ],
   "source": [
    "def run_agent(max_iterations: int = 10):\n",
    "    \"\"\"\n",
    "    Main agent loop that processes user requests.\n",
    "\n",
    "    Args:\n",
    "        max_iterations: Maximum number of interactions allowed\n",
    "    \"\"\"\n",
    "    # Initialize memory with agent rules\n",
    "    memory = agent_rules.copy()\n",
    "    iterations = 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" Study Helper Agent Started! (AI-POWERED)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"I can help you with:\")\n",
    "    print(\"  • Creating AI-generated quizzes\")\n",
    "    print(\"  • Summarizing text with AI\")\n",
    "    print(\"  • Explaining concepts intelligently\")\n",
    "    print(\"  • Saving and retrieving notes\")\n",
    "    print(\"\\nAll tools are powered by AI for better results!\")\n",
    "    print(\"Type 'quit' or 'exit' to end the session.\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    while iterations < max_iterations:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\n You: \").strip()\n",
    "\n",
    "        # Check for exit commands\n",
    "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "            user_input = \"Please terminate the session with a nice goodbye message.\"\n",
    "\n",
    "        if not user_input:\n",
    "            print(\"  Please enter a message.\")\n",
    "            continue\n",
    "\n",
    "        # Add user message to memory\n",
    "        memory.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Generate response from LLM\n",
    "        print(\"\\n Agent: Thinking...\")\n",
    "        response = generate_response(memory)\n",
    "        print(f\"\\n Agent Response:\\n{response}\")\n",
    "\n",
    "        # Parse the action from response\n",
    "        action = parse_action(response)\n",
    "        print(f\"\\n  Action: {action['tool_name']}\")\n",
    "\n",
    "        # Execute the appropriate tool\n",
    "        result = None\n",
    "\n",
    "        try:\n",
    "            if action[\"tool_name\"] == \"generate_quiz\":\n",
    "                result = generate_quiz(\n",
    "                    topic=action[\"args\"].get(\"topic\", \"\"),\n",
    "                    num_questions=action[\"args\"].get(\"num_questions\", 5)\n",
    "                )\n",
    "\n",
    "            elif action[\"tool_name\"] == \"summarize_text\":\n",
    "                result = summarize_text(\n",
    "                    text=action[\"args\"].get(\"text\", \"\"),\n",
    "                    max_sentences=action[\"args\"].get(\"max_sentences\", 3)\n",
    "                )\n",
    "\n",
    "            elif action[\"tool_name\"] == \"explain_concept\":\n",
    "                result = explain_concept(\n",
    "                    concept=action[\"args\"].get(\"concept\", \"\"),\n",
    "                    difficulty=action[\"args\"].get(\"difficulty\", \"simple\")\n",
    "                )\n",
    "\n",
    "            elif action[\"tool_name\"] == \"save_notes\":\n",
    "                result = save_notes(\n",
    "                    title=action[\"args\"].get(\"title\", \"\"),\n",
    "                    content=action[\"args\"].get(\"content\", \"\")\n",
    "                )\n",
    "\n",
    "            elif action[\"tool_name\"] == \"retrieve_notes\":\n",
    "                result = retrieve_notes(\n",
    "                    title=action[\"args\"].get(\"title\")\n",
    "                )\n",
    "\n",
    "            elif action[\"tool_name\"] == \"terminate\":\n",
    "                print(f\"\\n {action['args'].get('message', 'Session ended.')}\")\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"Thanks for using AI-Powered Study Helper! \")\n",
    "                print(\"=\"*60)\n",
    "                break\n",
    "\n",
    "            elif action[\"tool_name\"] == \"error\":\n",
    "                result = {\"error\": action[\"args\"][\"message\"]}\n",
    "\n",
    "            else:\n",
    "                result = {\"error\": f\"Unknown tool: {action['tool_name']}\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            result = {\"error\": f\"Error executing tool: {str(e)}\"}\n",
    "\n",
    "        # Display result\n",
    "        if result:\n",
    "            print(f\"\\n Result:\")\n",
    "            print(\"=\"*60)\n",
    "            # Pretty print the result\n",
    "            if isinstance(result, dict):\n",
    "                for key, value in result.items():\n",
    "                    if key not in ['status']:\n",
    "                        if isinstance(value, str) and len(value) > 200:\n",
    "                            print(f\"{key}:\\n{value}\\n\")\n",
    "                        else:\n",
    "                            print(f\"{key}: {value}\")\n",
    "            print(\"=\"*60)\n",
    "\n",
    "            # Update memory with assistant response and tool result\n",
    "            memory.append({\"role\": \"assistant\", \"content\": response})\n",
    "            memory.append({\"role\": \"user\", \"content\": json.dumps(result)})\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    if iterations >= max_iterations:\n",
    "        print(\"\\n  Maximum iterations reached. Session ended.\")\n",
    "\n",
    "print(\"✓ run_agent function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xjlu9NcQZWAb"
   },
   "source": [
    "---\n",
    "## Part 6: Run the Agent\n",
    "\n",
    "Now let's run the AI-Powered Study Helper agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75093,
     "status": "ok",
     "timestamp": 1770875566230,
     "user": {
      "displayName": "Mafia Nawaz",
      "userId": "17970888336776500782"
     },
     "user_tz": -300
    },
    "id": "OQb8H3C3ZWAc",
    "outputId": "808be9b7-1f6c-423c-8a06-2d62b722831d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " Study Helper Agent Started! (AI-POWERED)\n",
      "============================================================\n",
      "I can help you with:\n",
      "  • Creating AI-generated quizzes\n",
      "  • Summarizing text with AI\n",
      "  • Explaining concepts intelligently\n",
      "  • Saving and retrieving notes\n",
      "\n",
      "All tools are powered by AI for better results!\n",
      "Type 'quit' or 'exit' to end the session.\n",
      "============================================================\n",
      "\n",
      "\n",
      " You: Create a quiz about Neural Networks with 3 questions\n",
      "\n",
      " Agent: Thinking...\n",
      "\n",
      " Agent Response:\n",
      "```action\n",
      "{\n",
      "  \"tool_name\": \"generate_quiz\",\n",
      "  \"args\": {\"topic\": \"Neural Networks\", \"num_questions\": 3}\n",
      "}\n",
      "```\n",
      "\n",
      "  Action: generate_quiz\n",
      "    Generating 3 quiz questions about Neural Networks...\n",
      "\n",
      " Result:\n",
      "============================================================\n",
      "topic: Neural Networks\n",
      "num_questions: 3\n",
      "quiz_content:\n",
      "Q1: What is the primary function of the activation function in a neural network?\n",
      "A) To reduce the dimensionality of the input data\n",
      "B) To increase the complexity of the model\n",
      "C) To introduce non-linearity into the model, allowing it to learn and represent more complex relationships\n",
      "D) To decrease the learning rate of the model\n",
      "Correct: C\n",
      "Explanation: The activation function is a crucial component of a neural network, as it introduces non-linearity into the model, enabling it to learn and represent complex relationships between inputs and outputs.\n",
      "\n",
      "Q2: Which of the following types of neural networks is particularly well-suited for image classification tasks, due to its ability to preserve spatial relationships between input data?\n",
      "A) Recurrent Neural Network (RNN)\n",
      "B) Convolutional Neural Network (CNN)\n",
      "C) Autoencoder\n",
      "D) Restricted Boltzmann Machine (RBM)\n",
      "Correct: B\n",
      "Explanation: Convolutional Neural Networks (CNNs) are designed to process data with spatial hierarchies, making them particularly effective for image classification tasks, where preserving spatial relationships is crucial.\n",
      "\n",
      "Q3: What is the term for the process of adjusting the model's parameters to minimize the difference between the predicted output and the actual output, using backpropagation and an optimization algorithm?\n",
      "A) Forward propagation\n",
      "B) Backpropagation\n",
      "C) Model regularization\n",
      "D) Training or optimization\n",
      "Correct: D\n",
      "Explanation: The process of adjusting the model's parameters to minimize the difference between the predicted output and the actual output is known as training or optimization, which involves backpropagation and an optimization algorithm, such as stochastic gradient descent (SGD).\n",
      "\n",
      "message:  Generated 3 AI-powered questions about Neural Networks\n",
      "============================================================\n",
      "\n",
      " You: Explain recursion in detail\n",
      "\n",
      " Agent: Thinking...\n",
      "\n",
      " Agent Response:\n",
      "```action\n",
      "{\n",
      "  \"tool_name\": \"explain_concept\",\n",
      "  \"args\": {\"concept\": \"recursion\", \"difficulty\": \"detailed\"}\n",
      "}\n",
      "```\n",
      "\n",
      "  Action: explain_concept\n",
      "    Explaining 'recursion' at detailed level...\n",
      "\n",
      " Result:\n",
      "============================================================\n",
      "concept: recursion\n",
      "difficulty_level: detailed\n",
      "explanation:\n",
      "**Recursion: A Comprehensive Explanation**\n",
      "\n",
      "Recursion is a fundamental concept in computer science and mathematics that can be used to solve complex problems by breaking them down into smaller, more manageable sub-problems. It is a programming technique where a function calls itself repeatedly until it reaches a base case that stops the recursion.\n",
      "\n",
      "**Technical Aspects:**\n",
      "\n",
      "Recursion involves two main components:\n",
      "\n",
      "1. **Base Case:** A base case is a trivial case that can be solved directly, without calling the function again. It serves as a stopping point for the recursion.\n",
      "2. **Recursive Case:** A recursive case is a case that can be broken down into smaller sub-problems, which are then solved by calling the function again.\n",
      "\n",
      "When a function calls itself, it creates a new instance of itself, which is added to the system's call stack. The call stack is a region of memory that stores information about the active functions, including their parameters, local variables, and return addresses.\n",
      "\n",
      "**Theory:**\n",
      "\n",
      "Recursion is based on the principle of mathematical induction, which states that a statement can be proven true for all positive integers if:\n",
      "\n",
      "1. The statement is true for the smallest possible value (base case).\n",
      "2. If the statement is true for a given value, it is also true for the next value (recursive case).\n",
      "\n",
      "Recursion can be used to solve problems that have the following properties:\n",
      "\n",
      "1. **Optimal Substructure:** The problem can be broken down into smaller sub-problems, and the optimal solution to the larger problem can be constructed from the optimal solutions of the sub-problems.\n",
      "2. **Overlapping Sub-problems:** The sub-problems may have some overlap, meaning that some sub-problems may be identical or have similar solutions.\n",
      "\n",
      "**Practical Examples:**\n",
      "\n",
      "1. **Factorial Function:** The factorial function is a classic example of recursion. The factorial of a number `n` is defined as the product of all positive integers less than or equal to `n`. The recursive formula for the factorial function is:\n",
      "```\n",
      "factorial(n) = n * factorial(n-1)\n",
      "```\n",
      "The base case is when `n` is 0 or 1, in which case the function returns 1. For example, `factorial(5)` would be calculated as:\n",
      "```\n",
      "factorial(5) = 5 * factorial(4)\n",
      "= 5 * (4 * factorial(3))\n",
      "= 5 * (4 * (3 * factorial(2)))\n",
      "= 5 * (4 * (3 * (2 * factorial(1))))\n",
      "= 5 * (4 * (3 * (2 * 1)))\n",
      "= 120\n",
      "```\n",
      "2. **Fibonacci Sequence:** The Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding numbers:\n",
      "```\n",
      "0, 1, 1, 2, 3, 5, 8, 13, ...\n",
      "```\n",
      "The recursive formula for the Fibonacci sequence is:\n",
      "```\n",
      "fibonacci(n) = fibonacci(n-1) + fibonacci(n-2)\n",
      "```\n",
      "The base cases are when `n` is 0 or 1, in which case the function returns 0 or 1, respectively.\n",
      "3. **Tree Traversal:** Recursion can be used to traverse a tree data structure, such as a binary tree. For example, a function to traverse a binary tree might use the following recursive formula:\n",
      "```\n",
      "traverse(node) = {\n",
      "  if (node is null) return\n",
      "  traverse(node.left)\n",
      "  process(node.value)\n",
      "  traverse(node.right)\n",
      "}\n",
      "```\n",
      "**Key Takeaways:**\n",
      "\n",
      "1. **Recursion is a powerful technique for solving complex problems by breaking them down into smaller sub-problems.**\n",
      "2. **A recursive function must have a clear base case that stops the recursion, and a recursive case that breaks down the problem into smaller sub-problems.**\n",
      "3. **Recursion can be used to solve problems with optimal substructure and overlapping sub-problems, such as the factorial function, Fibonacci sequence, and tree traversal.**\n",
      "4. **Recursion can be less efficient than iteration in some cases, since it can lead to a large number of function calls and a deep call stack. However, it can also be more elegant and easier to understand for certain types of problems.**\n",
      "\n",
      "message:  Explained 'recursion' at detailed level\n",
      "============================================================\n",
      "\n",
      " You:  Summarize this: \"Machine learning is a subset of artificial intelligence...\"\n",
      "\n",
      " Agent: Thinking...\n",
      "\n",
      " Agent Response:\n",
      "```action\n",
      "{\n",
      "  \"tool_name\": \"summarize_text\",\n",
      "  \"args\": {\"text\": \"Machine learning is a subset of artificial intelligence...\", \"max_sentences\": 3}\n",
      "}\n",
      "```\n",
      "\n",
      "  Action: summarize_text\n",
      "    Summarizing text (target: 3 sentences)...\n",
      "\n",
      " Result:\n",
      "============================================================\n",
      "original_length: 8\n",
      "summary:\n",
      "Here is a summary of the text in approximately 3 sentences:\n",
      "Machine learning is a subset of artificial intelligence that enables systems to automatically improve their performance on a task without being explicitly programmed. This is achieved through the use of algorithms that allow the system to learn from data and make predictions or decisions. The goal of machine learning is to develop systems that can learn and adapt to new data, making it a key component of many modern technologies.\n",
      "\n",
      "Key points:\n",
      "* Machine learning is a subset of artificial intelligence\n",
      "* It enables systems to learn from data and improve their performance on a task\n",
      "* Machine learning uses algorithms to make predictions or decisions\n",
      "* It allows systems to learn and adapt to new data\n",
      "* It is a key component of many modern technologies\n",
      "\n",
      "target_sentences: 3\n",
      "message:  Text summarized successfully\n",
      "============================================================\n",
      "\n",
      " You: exit\n",
      "\n",
      " Agent: Thinking...\n",
      "\n",
      " Agent Response:\n",
      "```action\n",
      "{\n",
      "  \"tool_name\": \"terminate\",\n",
      "  \"args\": {\"message\": \"It was a pleasure assisting you! Have a great day and happy learning!\"}\n",
      "}\n",
      "```\n",
      "\n",
      "  Action: terminate\n",
      "\n",
      " It was a pleasure assisting you! Have a great day and happy learning!\n",
      "\n",
      "============================================================\n",
      "Thanks for using AI-Powered Study Helper! \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "run_agent(max_iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy0uoS_jZWAc"
   },
   "source": [
    "---\n",
    "## Example Interactions\n",
    "\n",
    "### Example 1: AI-Generated Quiz\n",
    "```\n",
    "You: Create a quiz about Neural Networks with 3 questions\n",
    "Agent: [Generates real quiz questions using AI]\n",
    "Result: Shows actual multiple-choice questions with explanations\n",
    "```\n",
    "\n",
    "### Example 2: AI Concept Explanation\n",
    "```\n",
    "You: Explain recursion in detail\n",
    "Agent: [Uses AI to explain with examples]\n",
    "Result: Detailed explanation with practical examples\n",
    "```\n",
    "\n",
    "### Example 3: AI Text Summarization\n",
    "```\n",
    "You: Summarize this: \"Machine learning is a subset of artificial intelligence...\"\n",
    "Agent: [AI analyzes and summarizes]\n",
    "Result: Concise summary with key points\n",
    "```\n",
    "\n",
    "### Example 4: Memory Chain\n",
    "```\n",
    "You: Explain machine learning in simple terms\n",
    "Agent: [AI explains]\n",
    "You: Now create a quiz about what you just explained\n",
    "Agent: [AI creates quiz based on previous explanation]\n",
    "```\n",
    "\n",
    "### Example 5: Save and Retrieve\n",
    "```\n",
    "You: Create a quiz about Python\n",
    "Agent: [Generates quiz]\n",
    "You: Save this quiz as \"Python Basics\"\n",
    "Agent: [Saves the quiz]\n",
    "You: Show me all my saved notes\n",
    "Agent: [Lists all saved notes]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHvEMcPlZWAd"
   },
   "source": [
    "##  Key Features\n",
    "\n",
    "### AI-Powered Tools:\n",
    "✅ **Smart Quiz Generation** - Creates real multiple-choice questions with explanations\n",
    "\n",
    "✅ **Intelligent Summarization** - AI analyzes and extracts key points\n",
    "\n",
    "✅ **Adaptive Explanations** - Adjusts complexity based on difficulty level\n",
    "\n",
    "✅ **Memory Persistence** - Save and retrieve study materials\n",
    "\n",
    "✅ **Context Awareness** - Remembers conversation history\n",
    "\n",
    "### Technical Features:\n",
    "✅ Comprehensive error handling\n",
    "\n",
    "✅ JSON parsing with validation\n",
    "\n",
    "✅ Agent loop with termination\n",
    "\n",
    "✅ Multi-API support (Groq/OpenAI)\n",
    "\n",
    "✅ Interactive CLI interface\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Setup**: Add your Groq API key\n",
    "2. **Run**: Execute all cells in order\n",
    "3. **Interact**: Type your requests naturally\n",
    "4. **Exit**: Type 'quit' or 'exit' when done\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
